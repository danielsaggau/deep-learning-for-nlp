---
title: "Everything_week1"
author: "Daniel Saggau"
date: "12/29/2020"
output: pdf_document
fontsize: 9 pt
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Woche 1 

# Einführung und Motivation 

Beispiele: 

Beispiel 1:

Einfluß auf Lesetest: potentzielle Einflüsse 

Model mit Y und gegebenen Kovariablen.

Beispiel 2: 

Risiko von Covid-19. 
Risikofaktoren für einen schweren Verlauf. 
Welche Faktoren sind relevant?
Variablenselektion ist eine zentrale Fragestellung.
Ergebnis: einige wenige Variablen spielen eine Rolle. LASSO; Boosting


Beispiel 3: 

Neuerkrankungen Covid-19
Zusammenhang anzahl Neuerkrankungen und Einflußgrößen.
Hier Model mit Poisson Regression.
Keine Normalverteilung gegeben.
Bruchpunkte wo sich der Verlauf verändert.

Allgemein haben wir die Struktur einer Normalverteilung aber mit Linkfunktion die den Erwartungswert verbindet. 

Beispiel 4:

Midlife Crisis: Panel Daten über subjektive Lebenszufriedenheit. 
gemischte Modell mit verschiedenen Effekten. 

Beispiel 5:

Wahlanalyse auf Kreisebene.
Gibt es zusammenhänge zwischen Wahlbezirken und Wahlverhalten ?

Beispiel 6: 

Bisher Zusammenhang zwischen Mittelwert.
Hier Interessiert an den verschiedenen Quantilen.
Referenzkurve für BMI.
Beyond Mean regression:Quantilregression und GAMLSS.
GAMLSS: Generalized Additive Models for Location.

Beispiel 7:

Wahl und Personenmerkmale: 
Palette an Auswahl.
Multinominales Logit-Modell mit k Kategorien.

Beispiel 8:

Überlebenszeit Modellen von Intensivpatienten.
Cox-Modell 

Beispiel 9:

Modell mit additivem Messfehler

Unterschied: Machine Learninf und Regression 

Regression. Schätze Beziehung zwischen x und Y.
Interpretiere und prüfe die Beziehung. 
Nutze die Beziehung zur Prognose. 

**Machine Learning:**
Regression des supervised Learning Y: Target, Output 
x: Feature, inout Prinzip: Lerne (trainiere Modell) aus Daten Beziehung zwischen x und Y
Nutze Beziehung Primär zur Prognose von Y aus x.
Y binär und diskret: Klassifikationsproblem


# 1-2 Lineare Modell 


```{r}
library(ggplot2)

beta0=3
beta1=1
sigma=2
x = seq(from=0, by =0.5, to=10)
y = beta0 + beta1 * x +rnorm(length(x),sd=sigma)
dat = data.frame(y,x)
ggplot(dat, aes(x=x, y=y)) + geom_point()+
  geom_abline(intercept = beta0, slope = beta1, col ="red") + ylim(0,20)

summary(lm(y~x))
```

Das Mutiple lineare Regressionsmodell: 

Siehe Fahrmeir Kap. 3.1-3.3
$Y_i=\beta_0 +\beta_1x_{i1}+ \epsilon_i$
i = 1...n

Stochastische Annahme über Störterm i.

$E(\epsilon_i) = 0$
$E(\epsilon) = 0$
$V(\epsilon)=\sigma^2$
Die Störterme sind unabhängig: ${\epsilon_i | i=1...n}$
Daraus folgt $V(\epsilon)= \sigma^2I$
Die Störterme sind sind normalverteilt 
$\epsilon_I = N(0, \sigma^2)$
$\epsilon = N(0, \sigma^2I)$

Dann haben wir die Erwartungswertdarstellung: 

Linearkombination der X-Variablen 

$E(Y)=\beta_0 +\beta_1x_{1}$

Man muss Vorsichtig sein, da es auch experimentalbedingungen gibt. 
Es ist die Entscheidende stärke, dass man die Variablen interpretieren kann. 
Man hält die anderen Variablen.
Herausrechnen von anderen Einflüßen ist die große Stärke.

Schätzung im linearen Modell: KQ Schätzer 

Wir betrachten Modell 1.1.

siehe Folien 38

$E(\hat{\beta})=\beta$

Konfidenzintervalle können nun bestimmt werden.

ML Schätzer 


Likelihood Quotienten Test 



Quadratsummenzerlegung:

rg(X) = p+1 =: p'
SST = SSE + SSM


Interpretation: 

SST = Gesamt-Streuung  
SSE = Fehler
SSM =

Bestimmtheitsgrad:

r^2=SSM/SST 


```{r}
library(haven)
library(foreign)
library(effects)

dat1 = read.dta("~/Downloads/soep_lebensz.dta")
summary(dat1)

dat2004 = dat1[dat1$jahr==2004,]
summary(dat2004)
dat2004$lz = as.numeric(dat2004$lebensz_org) -4
dat2004$gesund = as.numeric(dat2004$gesund_org) -4

boxplot(dat2004$lz)

table(dat2004$gesund)

reg1 = lm(lz~gesund, data = dat2004)
summary(reg1)

reg2 = lm(lz~gesund + anz_kind +bildung, data = dat2004)
summary(reg2)
```


# 1.3 Dummy Variablen und Interaktionen 

* Umgang mit diskreten Variablen und Interaktionen 
* Ausgangspunkt ist das lineare Modell
* Das Lineare Modell in der Erwartungswertdarstellung 

$E(Y)=\beta_0+\beta_1x_1$

Es wird schwieriger, wenn wir mehrere kategorien haben. 
Da implementiert man dann dummy variablen(0,1).
Wird bei nominalen Merkmalen so definiert, dass der wert 1 ist wenn die variable zu der Kategorie gehört und 0 wenn er nicht dazu gehört.
Modell mit Referenzkategorie K:
Eine konstante und anderen beiden 0,1.

```{r}
dat2004$anz_kind = as.factor(dat2004$anz_kind)
reg3= lm(lz~ anz_kind+ sex + gesund_org, data = dat2004)
summary(reg3)
plot(allEffects(reg3), ylim = c(4,10))
```

## Interaktion 

Wichtig in der Modellierung: 
Der Einfluss einer Variable hängt von dem Wert einer anderen Variable ab. 
Beispiele Effekt ist unterscheidlich zwischen Männern und Frauen. 
Man redet von Synergie-effekten.

Der Unterschied in der e.g. Gesundheit wird durch die Variable Geschlecht moderiert. 
Interaktionen lassen sich durch Aufnahme von Produkttermen.

Interaktion bedeutet Steigung verschieden. 

Wilkonson-Rogers Notation:

```{r}
reg4 = lm(lz~gesund + sex + gesund*sex, data =dat2004) 
summary(reg4)
plot(allEffects(reg4), ylim = c(4,10))

reg5 = lm(lz~gesund+bildung+sex+bildung*sex, data =dat2004)
summary(reg5)
plot(allEffects(reg5), ylim = c(4,10))
```

